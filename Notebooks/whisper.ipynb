{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (0.14.1)\n",
      "Requirement already satisfied: torchaudio in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: requests in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: numpy in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->torchvision) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->torchvision) (3.4)\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /private/var/folders/ls/f554v809331fb99_zk8rznhr0000gn/T/pip-req-build-3o3iu9wi\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /private/var/folders/ls/f554v809331fb99_zk8rznhr0000gn/T/pip-req-build-3o3iu9wi\n",
      "  Resolved https://github.com/huggingface/transformers to commit 9ddf4f4f03608095224cd3354b62c6f7d0d4b009\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: filelock in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: requests in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev0) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (3.4)\n",
      "Requirement already satisfied: librosa in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (0.10.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (0.3.3)\n",
      "Requirement already satisfied: joblib>=0.14 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (1.0.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (4.5.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (0.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: pooch>=1.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from librosa) (1.23.5)\n",
      "Requirement already satisfied: importlib-metadata in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (6.0.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (56.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from pooch>=1.0->librosa) (23.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from pooch>=1.0->librosa) (2.28.2)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from importlib-metadata->numba>=0.51.0->librosa) (3.15.0)\n",
      "zsh:1: 0.30 not found\n",
      "Requirement already satisfied: jiwer in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (2.5.1)\n",
      "Requirement already satisfied: levenshtein==0.20.2 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from jiwer) (0.20.2)\n",
      "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from levenshtein==0.20.2->jiwer) (2.13.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install librosa\n",
    "!pip install evaluate>=0.30\n",
    "!pip install jiwer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (2.10.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: aiohttp in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: multiprocess in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: packaging in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (0.12.1)\n",
      "Requirement already satisfied: xxhash in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: pandas in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import interleave_datasets, load_dataset\n",
    "\n",
    "def load_streaming_dataset(dataset_name, dataset_config_name, split, **kwargs):\n",
    "    if \"+\" in split:\n",
    "        # load multiple splits separated by the `+` symbol *with* streaming mode\n",
    "        dataset_splits = [load_dataset(dataset_name, dataset_config_name, split=split_name, streaming=True, **kwargs) for split_name in split.split(\"+\")]\n",
    "        # interleave multiple splits to form one dataset\n",
    "        interleaved_dataset = interleave_datasets(dataset_splits)\n",
    "        return interleaved_dataset\n",
    "    else:\n",
    "        # load a single split *with* streaming mode\n",
    "        dataset = load_dataset(dataset_name, dataset_config_name, split=split, streaming=True, **kwargs)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import IterableDatasetDict\n",
    "\n",
    "raw_datasets = IterableDatasetDict()\n",
    "\n",
    "raw_datasets[\"train\"] = load_streaming_dataset(\"mozilla-foundation/common_voice_11_0\", \"fr\", split=\"train\", use_auth_token=True)  # set split=\"train+validation\" for low-resource\n",
    "raw_datasets[\"test\"] = load_streaming_dataset(\"mozilla-foundation/common_voice_11_0\", \"fr\", split=\"test\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /private/var/folders/ls/f554v809331fb99_zk8rznhr0000gn/T/pip-req-build-2a__zq93\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /private/var/folders/ls/f554v809331fb99_zk8rznhr0000gn/T/pip-req-build-2a__zq93\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mFound existing installation: transformers 4.27.0.dev0\n",
      "Uninstalling transformers-4.27.0.dev0:\n",
      "  Would remove:\n",
      "    /Users/marouaneelbouazzaoui/whisper/hf_env/bin/transformers-cli\n",
      "    /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages/transformers-4.27.0.dev0.dist-info/*\n",
      "    /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages/transformers/*\n",
      "Proceed (Y/n)? "
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (4.27.0.dev0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: requests in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests->transformers) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Processor and Pre-Process Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"French\", task=\"transcribe\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample from 48kHz to 16kHz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "raw_datasets = raw_datasets.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.iterable_dataset.IterableDataset object at 0x141ca57f0>\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(raw_datasets.values())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and use function to prepare our data ready for the Whisper AI model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and (possibly) resample audio data to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    # compute input length of audio sample in seconds\n",
    "    batch[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
    "    \n",
    "    # optional pre-processing steps\n",
    "    transcription = batch[\"sentence\"]\n",
    "    if do_lower_case:\n",
    "        transcription = transcription.lower()\n",
    "    if do_remove_punctuation:\n",
    "        transcription = normalizer(transcription).strip()\n",
    "    \n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = processor.tokenizer(transcription).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_datasets = raw_datasets.map(prepare_dataset, remove_columns=list(next(iter(raw_datasets.values())).features)).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_datasets[\"train\"] = vectorized_datasets[\"train\"].shuffle(\n",
    "    buffer_size=500,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 30.0\n",
    "\n",
    "def is_audio_in_length_range(length):\n",
    "    return length < max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_datasets[\"train\"] = vectorized_datasets[\"train\"].filter(\n",
    "    is_audio_in_length_range,\n",
    "    input_columns=[\"input_length\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (23.0.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (2.28.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (2.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (0.12.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: dill in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: multiprocess in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: xxhash in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: pandas in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (2023.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: packaging in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: filelock in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate with the 'normalised' WER\n",
    "do_normalize_eval = True\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    if do_normalize_eval:\n",
    "        pred_str = [normalizer(pred) for pred in pred_str]\n",
    "        label_str = [normalizer(label) for label in label_str]\n",
    "        # filtering step to only evaluate the samples that correspond to non-zero references:\n",
    "        pred_str = [pred_str[i] for i in range(len(pred_str)) if len(label_str[i]) > 0]\n",
    "        label_str = [label_str[i] for i in range(len(label_str)) if len(label_str[i]) > 0]\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Pre-Trained Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch              1.13.1\n",
      "torchaudio         0.13.1\n",
      "torchvision        0.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip list| grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from torch) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 967M/967M [02:15<00:00, 7.16MB/s] \n",
      "Downloading (…)neration_config.json: 100%|██████████| 3.49k/3.49k [00:00<00:00, 421kB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE fp16=True ,If you want to run it on the CPU\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    per_device_train_batch_size=64,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=5000,\n",
    "    gradient_checkpointing=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then define a custom Callback that is called by the 🤗 Trainer on the end of each epoch. The Callback reinitialises and reshuffles the streaming dataset at the beginning of each new epoch - this gives different shuffling across our subsets for every epoch.\n",
    "from transformers import TrainerCallback\n",
    "from transformers.trainer_pt_utils import IterableDatasetShard\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "# trainer callback to reinitialise and reshuffle the streamable datasets at the beginning of each epoch\n",
    "class ShuffleCallback(TrainerCallback):\n",
    "    def on_epoch_begin(self, args, state, control, train_dataloader, **kwargs):\n",
    "        if isinstance(train_dataloader.dataset, IterableDatasetShard):\n",
    "            pass  # set_epoch() is handled by the Trainer\n",
    "        elif isinstance(train_dataloader.dataset, IterableDataset):\n",
    "            train_dataloader.dataset.set_epoch(train_dataloader.dataset._epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (2.6)\n",
      "Requirement already satisfied: packaging in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from tensorboardX) (23.0)\n",
      "Requirement already satisfied: numpy in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from tensorboardX) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4,>=3.8.0 in /Users/marouaneelbouazzaoui/whisper/hf_env/lib/python3.8/site-packages (from tensorboardX) (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'common_voice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# We can forward the training arguments to the 🤗 Trainer along with our model, dataset, data collator, compute_metrics function and custom callback:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m Seq2SeqTrainer\n\u001b[1;32m      4\u001b[0m trainer \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m      5\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m      6\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m----> 7\u001b[0m     train_dataset\u001b[39m=\u001b[39mcommon_voice[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m     eval_dataset\u001b[39m=\u001b[39mcommon_voice[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m     data_collator\u001b[39m=\u001b[39mdata_collator,\n\u001b[1;32m     10\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[1;32m     11\u001b[0m     tokenizer\u001b[39m=\u001b[39mprocessor\u001b[39m.\u001b[39mfeature_extractor,\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'common_voice' is not defined"
     ]
    }
   ],
   "source": [
    "# We can forward the training arguments to the 🤗 Trainer along with our model, dataset, data collator, compute_metrics function and custom callback:\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=common_voice[\"train\"],\n",
    "    eval_dataset=common_voice[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e7bff2cc3adfaca8033ff3605b2aa02342949e4611ffdd90d25c75e67e04b7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
